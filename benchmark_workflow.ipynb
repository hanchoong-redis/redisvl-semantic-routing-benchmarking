{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a6ba1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q sentence-transformers ranx redisvl \"redis-retrieval-optimizer>=0.2.0\" datasets pandas openai scikit-learn h5py tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ecff2b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7b92b",
   "metadata": {},
   "source": [
    "## Run a Redis instance\n",
    "\n",
    "#### Mac\n",
    "\n",
    "Remember to point at 6380, not 6379\n",
    "```bash\n",
    "docker run -d --name redis-stack \\\n",
    "  -p 6380:6379 -p 8001:8001 \\\n",
    "  -v redis-data:/data \\\n",
    "  redis/redis-stack:latest\n",
    "\n",
    "```\n",
    "#### For Colab\n",
    "Use the shell script below to download, extract, and install [Redis Stack](https://redis.io/docs/getting-started/install-stack/) directly from the Redis package archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "%%sh\n",
    "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
    "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
    "sudo apt-get update  > /dev/null 2>&1\n",
    "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
    "redis-stack-server --daemonize yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce384584",
   "metadata": {},
   "source": [
    "### Define the Redis Connection URL\n",
    "\n",
    "By default this notebook connects to the local instance of Redis Stack. **If you have your own Redis Enterprise instance** - replace REDIS_PASSWORD, REDIS_HOST and REDIS_PORT values with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414b8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, io\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\") # ex: \"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6380\")      # ex: 18374\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")  \n",
    "REDIS_DB = os.getenv(\"REDIS_DB\", 0)\n",
    "\n",
    "# If SSL is enabled on the endpoint, use rediss:// as the URL prefix\n",
    "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe5691",
   "metadata": {},
   "source": [
    "# Set Credentials for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3fa9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c083da",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20433a8f",
   "metadata": {},
   "source": [
    "## Metrics Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b05a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pbar'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpbar\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pbar'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "import h5py, numpy as np\n",
    "def format_timestamp(ts=None):\n",
    "    if ts is None:\n",
    "        ts = datetime.now()\n",
    "    elif isinstance(ts, (int, float)):\n",
    "        ts = datetime.fromtimestamp(ts)\n",
    "    return ts.strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.timings = {}\n",
    "\n",
    "    def timeit(self, name):\n",
    "        class _T:\n",
    "            def __enter__(_self):\n",
    "                _self.start = time.perf_counter()\n",
    "            def __exit__(_self, *a):\n",
    "                end=round(time.perf_counter() - _self.start, 3)\n",
    "                self.timings[name] = end\n",
    "        return _T()\n",
    "\n",
    "def classification_metrics(preds: list[str], labels: list[str]) -> dict:\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision_macro\": precision_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"recall_macro\": recall_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"confusion_matrix\": confusion_matrix(labels, preds).tolist(),\n",
    "        \"classification_report\": classification_report(labels, preds, zero_division=0, output_dict=True)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def print_experiment_summary(eval_metrics, \n",
    "                             router_config, timings, redis_schema=None, redis_index_info=None,\n",
    "                             experiment_notes=\"NA\", experiment_name=\"experiment\", \n",
    "                             print_output=True, save_output=True):\n",
    "    lines = []\n",
    "    lines.append(\"=== Experiment Summary: Semantic Routing Classification ===\\n\")\n",
    "\n",
    "    lines.append(f\"Timestamp         : {format_timestamp()}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    lines.append(f\"Experiment Notes  : {experiment_notes}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Data Config\n",
    "    lines.append(\"DATA CONFIGURATION\")\n",
    "    lines.append(f\"Router Name       : {router_config.get('name')}\")\n",
    "    lines.append(f\"Batch Size        : {router_config.get('batch_size')}\")\n",
    "    lines.append(f\"Dataset Repo ID    : {router_config.get('dataset_repo_id')}\")\n",
    "    lines.append(f\"Dataset Domain    : {router_config.get('dataset_domain')}\")\n",
    "    lines.append(f\"Dataset Name      : {router_config.get('dataset_name')}\")\n",
    "    lines.append(f\"Train Limit       : {router_config.get('train_limit')}\")\n",
    "    lines.append(f\"Test Limit        : {router_config.get('test_limit')}\")\n",
    "    vec_cfg = router_config.get('vectorizer_config', {})\n",
    "    lines.append(f\"Vector Dimensions : {vec_cfg.get('dimensions')}\")\n",
    "    lines.append(f\"Embedding Model   : {vec_cfg.get('OPENAI_MODEL')}\\n\")\n",
    "\n",
    "    # Redis Schema\n",
    "    if redis_schema:\n",
    "        idx = redis_schema.get('index', {})\n",
    "        lines.append(\"REDIS SCHEMA\")\n",
    "        lines.append(f\"Index Name        : {idx.get('name')}\")\n",
    "        lines.append(f\"Prefix            : {idx.get('prefix')}\")\n",
    "        lines.append(f\"Storage Type      : {idx.get('storage_type')}\")\n",
    "        lines.append(\"Fields:\")\n",
    "        for f in redis_schema.get('fields', []):\n",
    "            if f['type'] == 'vector':\n",
    "                attrs = f.get('attrs', {})\n",
    "                lines.append(f\"  - {f['name']} ({f['type']})  dims={attrs.get('dims')}, metric={attrs.get('distance_metric')}, algo={attrs.get('algorithm')}\")\n",
    "            else:\n",
    "                lines.append(f\"  - {f['name']} ({f['type']})\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Redis Index Info\n",
    "    if redis_index_info:\n",
    "        lines.append(\"REDIS INDEX INFO\")\n",
    "        lines.append(f\"Documents         : {redis_index_info['num_docs']}\")\n",
    "        lines.append(f\"Max Doc ID        : {redis_index_info['max_doc_id']}\")\n",
    "        lines.append(f\"Num Terms         : {redis_index_info['num_terms']}\")\n",
    "        lines.append(f\"Num Records       : {redis_index_info['num_records']}\")\n",
    "        lines.append(f\"Inverted Size (MB): {float(redis_index_info['inverted_sz_mb']):.6f}\")\n",
    "        lines.append(f\"Vector Index (MB) : {float(redis_index_info['vector_index_sz_mb']):.6f}\\n\")\n",
    "    else:\n",
    "        lines.append(\"No index info available\")\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    lines.append(\"EVALUATION METRICS\")\n",
    "    lines.append(f\"Accuracy          : {eval_metrics['accuracy']:.4f}\")\n",
    "    lines.append(f\"Precision (macro) : {eval_metrics['precision_macro']:.4f}\")\n",
    "    lines.append(f\"Recall (macro)    : {eval_metrics['recall_macro']:.4f}\")\n",
    "    lines.append(f\"F1 (macro)        : {eval_metrics['f1_macro']:.4f}\\n\")\n",
    "\n",
    "    cm = eval_metrics['confusion_matrix']\n",
    "    lines.append(\"CONFUSION MATRIX [ [TP_0, FP_0], [FN_1, TP_1] ]\")\n",
    "    lines.append(f\"  {cm[0]}\")\n",
    "    lines.append(f\"  {cm[1]}\\n\")\n",
    "\n",
    "    lines.append(\"CLASSIFICATION REPORT\")\n",
    "    report = eval_metrics['classification_report']\n",
    "    for label, metrics in report.items():\n",
    "        if label in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "            continue\n",
    "        lines.append(f\"Class {label}: \"\n",
    "                     f\"Precision={metrics['precision']:.3f}, \"\n",
    "                     f\"Recall={metrics['recall']:.3f}, \"\n",
    "                     f\"F1={metrics['f1-score']:.3f}, \"\n",
    "                     f\"Support={int(metrics['support'])}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    macro = report.get('macro avg', {})\n",
    "    lines.append(\"Macro Avg:\")\n",
    "    lines.append(f\"  Precision={macro.get('precision', 0):.3f}, \"\n",
    "                 f\"Recall={macro.get('recall', 0):.3f}, \"\n",
    "                 f\"F1={macro.get('f1-score', 0):.3f}\\n\")\n",
    "\n",
    "    # Timings\n",
    "    lines.append(\"TIMINGS (seconds)\")\n",
    "    total=sum(timings.values())\n",
    "    for k, v in timings.items():\n",
    "        lines.append(f\"{k:<45}: {v:.3f}\")\n",
    "    lines.append(f\"Total: {total:.3f}\")\n",
    "    lines.append(\"\\n=============================================================\\n\")\n",
    "\n",
    "    output_str = \"\\n\".join(lines)\n",
    "\n",
    "    if print_output:\n",
    "        print(output_str)\n",
    "\n",
    "    if save_output:\n",
    "        os.makedirs(\"experiments\", exist_ok=True)\n",
    "        path = os.path.join(\"experiments\", f\"{format_timestamp()}_{experiment_name}.txt\")\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(output_str)\n",
    "\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c6e83",
   "metadata": {},
   "source": [
    "## OpenAI Embedding and Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469ab400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "import h5py, numpy as np\n",
    "\n",
    "def save_embeddings_h5(\n",
    "    path: str,\n",
    "    labels: List[Any],\n",
    "    embeds: List[List[float]],\n",
    "    meta: Optional[Dict] = None\n",
    ") -> None:\n",
    "    E = np.asarray(embeds, dtype=\"float32\")\n",
    "    n, d = E.shape\n",
    "    L = np.asarray([str(l) for l in labels], dtype=h5py.string_dtype(\"utf-8\"))\n",
    "    if len(L) != n:\n",
    "        raise ValueError(\"labels length must match number of embeddings\")\n",
    "\n",
    "    with h5py.File(path, \"a\") as f:\n",
    "        if \"embeddings\" not in f:\n",
    "            f.create_dataset(\"embeddings\", data=E, maxshape=(None, d),\n",
    "                             chunks=True, compression=\"gzip\", compression_opts=4)\n",
    "            f.create_dataset(\"labels\", data=L, maxshape=(None,),\n",
    "                             chunks=True, compression=\"gzip\", compression_opts=4)\n",
    "            if meta:\n",
    "                for k, v in meta.items():\n",
    "                    f.attrs[k] = v\n",
    "        else:\n",
    "            de, dl = f[\"embeddings\"], f[\"labels\"]\n",
    "            if de.shape[1] != d:\n",
    "                raise ValueError(f\"dim mismatch: file {de.shape[1]} vs new {d}\")\n",
    "            start = de.shape[0]\n",
    "            de.resize(start + n, axis=0)\n",
    "            dl.resize(start + n, axis=0)\n",
    "            de[start:start+n] = E\n",
    "            dl[start:start+n] = L\n",
    "\n",
    "def load_embeddings_h5(path: str, n: Optional[int] = None) -> tuple[list[list[float]], list[str]]:\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for name in (\"embeddings\", \"labels\"):\n",
    "            if name not in f:\n",
    "                raise ValueError(f\"File missing '{name}' dataset\")\n",
    "        de, dl = f[\"embeddings\"], f[\"labels\"]\n",
    "        total = de.shape[0]\n",
    "        end = total if n is None else min(total, n)\n",
    "        vectors = de[:end]\n",
    "        labels = dl.asstr()[:end]\n",
    "    return vectors.tolist(), labels.tolist()\n",
    "\n",
    "def get_batch_embeddings(\n",
    "    text_list: list[str], \n",
    "    batch_size: int = 512,\n",
    "    dimensions: int = 128,\n",
    "    model: str = \"text-embedding-3-small\",\n",
    "    show_bar: bool = True\n",
    ") -> list[list[float]]:\n",
    "    client = OpenAI()\n",
    "    embeddings: List[List[float]] = []\n",
    "    texts = text_list\n",
    "    iterator = range(0, len(texts), batch_size)\n",
    "    pbar = tqdm(total=len(texts), unit=\"emb\", desc=\"Embedding\", disable=not show_bar)\n",
    "    try:\n",
    "        for i in iterator:\n",
    "            batch = texts[i:i + batch_size]\n",
    "            resp = client.embeddings.create(input=batch, model=model, dimensions=dimensions)\n",
    "            embeddings.extend([d.embedding for d in resp.data])\n",
    "            pbar.update(len(batch))\n",
    "    finally:\n",
    "        pbar.close()\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_batch_embeddings_to_h5(\n",
    "    out_path: str,\n",
    "    text_list: list[str],\n",
    "    labels_list: list[str],\n",
    "    batch_size: int = 512,\n",
    "    dimensions: int = 128,\n",
    "    model: str = \"text-embedding-3-small\",\n",
    "    show_bar: bool = True,\n",
    "    meta: Optional[Dict] = None,\n",
    "    return_data: bool = False,\n",
    "    append_existing: bool = False,\n",
    ") -> Optional[Tuple[list[list[float]], list[str]]]:\n",
    "    if len(text_list) != len(labels_list):\n",
    "        raise ValueError(\"text_list and labels_list must be same length\")\n",
    "\n",
    "    if os.path.exists(out_path) and not append_existing:\n",
    "        print(f\"File '{out_path}' already exists. Skipping embedding generation.\")\n",
    "        return None\n",
    "\n",
    "    client = OpenAI()\n",
    "    ret_E: List[List[float]] = []\n",
    "    ret_L: List[str] = []\n",
    "\n",
    "    iterator = range(0, len(text_list), batch_size)\n",
    "    pbar = tqdm(total=len(text_list), unit=\"emb\", desc=\"Embedding\", disable=not show_bar)\n",
    "\n",
    "    try:\n",
    "        for i in iterator:\n",
    "            batch_t = text_list[i:i + batch_size]\n",
    "            batch_l = labels_list[i:i + batch_size]\n",
    "            resp = client.embeddings.create(input=batch_t, model=model, dimensions=dimensions)\n",
    "            batch_e = [d.embedding for d in resp.data]\n",
    "\n",
    "            save_embeddings_h5(out_path, batch_l, batch_e, meta=meta)\n",
    "\n",
    "            if return_data:\n",
    "                ret_E.extend(batch_e)\n",
    "                ret_L.extend([str(x) for x in batch_l])\n",
    "\n",
    "            pbar.update(len(batch_t))\n",
    "    finally:\n",
    "        pbar.close()\n",
    "\n",
    "    return (ret_E, ret_L) if return_data else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae20a4b",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df99bf8",
   "metadata": {},
   "source": [
    "## Option 1: Custom Semantic Router - Direct Redis access - Allows for trying out techniques with Numpy Arrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e302b7d",
   "metadata": {},
   "source": [
    "### Select and Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ef6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from datasets import load_dataset\n",
    "\n",
    "# See dataset page @ https://huggingface.co/datasets/ + repo_id\n",
    "eval_datasets={\n",
    "                \"Topic\": {\n",
    "                    \"DBLP\":{\n",
    "                        \"repo_id\": \"waashk/dblp\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "                      }\n",
    "                    },\n",
    "                \"Sentiment\": {\n",
    "                    \"MPQA\":{\n",
    "                        \"repo_id\": \"jxm/mpqa\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"sentence\",\n",
    "                        \"label_col\": \"label\"\n",
    "                    }\n",
    "                }\n",
    "              }\n",
    "\n",
    "router_config = {\n",
    "    \"name\": \"test\",\n",
    "    \"batch_size\": 1024,\n",
    "    \"vectorizer_config\":{\n",
    "        \"dimensions\":128,\n",
    "        \"OPENAI_API_KEY\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"OPENAI_MODEL\": \"text-embedding-3-small\"\n",
    "    },\n",
    "    \"dataset_domain\": \"Sentiment\",\n",
    "    \"dataset_name\": \"MPQA\",\n",
    "}\n",
    "\n",
    "redis_schema = {\n",
    "    \"index\": {\n",
    "        \"name\": \"MPQA\",\n",
    "        \"prefix\": \"test1\",\n",
    "        \"storage_type\": \"hash\",\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"label\", \"type\": \"tag\"},\n",
    "        {\n",
    "            \"name\": \"vector\",\n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"dims\": router_config[\"vectorizer_config\"][\"dimensions\"],\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \"algorithm\": \"hnsw\",\n",
    "                \"datatype\": \"float32\"\n",
    "            }\n",
    "\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "experiment_notes = \"\"\n",
    "\n",
    "timer=Timer()\n",
    "\n",
    "with timer.timeit(\"load_dataset\"):\n",
    "    dataset_repo_id = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"repo_id\"]\n",
    "    dataset_train_lbl = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"train_lbl\"]\n",
    "    dataset_test_lbl = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"test_lbl\"]\n",
    "    dataset_text_col = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"text_col\"]\n",
    "    dataset_label_col = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"label_col\"]\n",
    "\n",
    "    dataset = load_dataset(dataset_repo_id)\n",
    "    train_data = dataset[dataset_train_lbl]\n",
    "    test_data = dataset[dataset_test_lbl]\n",
    "\n",
    "    router_config.update({\"dataset_repo_id\":dataset_repo_id})\n",
    "    router_config.update({\"train_limit\":train_data.num_rows})\n",
    "    router_config.update({\"test_limit\":test_data.num_rows})\n",
    "\n",
    "# Define Experiment Names\n",
    "safe_repo = dataset_repo_id.replace(\"/\", \"-\")\n",
    "experiment_name = f'{router_config[\"name\"]}_{safe_repo}_{router_config[\"vectorizer_config\"][\"OPENAI_MODEL\"]}_{router_config[\"vectorizer_config\"][\"dimensions\"]}'\n",
    "train_filepath = f'embeddings/{experiment_name}_{dataset_train_lbl}_{str(train_data.num_rows)}.h5'\n",
    "test_filepath  = f'embeddings/{experiment_name}_{dataset_test_lbl}_{str(test_data.num_rows)}.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49e598",
   "metadata": {},
   "source": [
    "### Pre-Generate Embeddings for Train and Test Data, Save to Embeddings Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a212b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'embeddings/test_jxm-mpqa_text-embedding-3-small_128_train_8603.h5' already exists. Skipping embedding generation.\n",
      "File 'embeddings/test_jxm-mpqa_text-embedding-3-small_128_test_2000.h5' already exists. Skipping embedding generation.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "\n",
    "with timer.timeit(\"Embed and Save Train Data\"):\n",
    "    train_embeddings = get_batch_embeddings_to_h5(out_path=train_filepath,\n",
    "                                                text_list=train_data[dataset_text_col],\n",
    "                                                labels_list=train_data[dataset_label_col],\n",
    "                                                batch_size=router_config[\"batch_size\"],\n",
    "                                                dimensions=router_config[\"vectorizer_config\"][\"dimensions\"],\n",
    "                                                model=router_config[\"vectorizer_config\"][\"OPENAI_MODEL\"])\n",
    "\n",
    "with timer.timeit(\"Embed and Save Test Data\"):\n",
    "    test_embeddings = get_batch_embeddings_to_h5(out_path=test_filepath,\n",
    "                                                text_list=test_data[dataset_text_col],\n",
    "                                                labels_list=test_data[dataset_label_col],\n",
    "                                                batch_size=router_config[\"batch_size\"],\n",
    "                                                dimensions=router_config[\"vectorizer_config\"][\"dimensions\"],\n",
    "                                                model=router_config[\"vectorizer_config\"][\"OPENAI_MODEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19502e9b",
   "metadata": {},
   "source": [
    "### Load and Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1ff508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import redis\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.index import SearchIndex\n",
    "\n",
    "def _kmeans(x, k, iters=20, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    k = min(k, len(x))\n",
    "    idx = rng.choice(len(x), size=k, replace=False)\n",
    "    c = x[idx].copy()\n",
    "    for _ in range(iters):\n",
    "        d = ((x[:, None, :] - c[None, :, :])**2).sum(-1)\n",
    "        a = d.argmin(1)\n",
    "        new_c = []\n",
    "        for j in range(k):\n",
    "            sj = (a == j)\n",
    "            if sj.any():\n",
    "                new_c.append(x[sj].mean(0))\n",
    "            else:\n",
    "                new_c.append(c[rng.integers(0, k)])\n",
    "        new_c = np.stack(new_c, 0)\n",
    "        if np.allclose(new_c, c):\n",
    "            break\n",
    "        c = new_c\n",
    "    return c, a\n",
    "\n",
    "def build_multi_prototypes(vectors, labels, mask=None, k_per_class=1, \n",
    "                           max_points_per_proto=None, normalize=True, seed=0):\n",
    "    \"\"\"\n",
    "    If max_points_per_proto is set, k for class c becomes ceil(n_c / max_points_per_proto).\n",
    "    Otherwise use fixed k_per_class.\n",
    "    \"\"\"\n",
    "    labels = np.asarray(labels)\n",
    "    V = np.asarray(vectors, dtype=np.float32)\n",
    "    if mask is None:\n",
    "        mask = np.linalg.norm(V, axis=1) > 0\n",
    "    V, L = V[mask], labels[mask]\n",
    "\n",
    "    out = []\n",
    "    for cls in np.unique(L):\n",
    "        sel = (L == cls)\n",
    "        X = V[sel]\n",
    "        if len(X) == 0:\n",
    "            continue\n",
    "\n",
    "        if max_points_per_proto is not None and max_points_per_proto > 0:\n",
    "            k = int(np.ceil(len(X) / max_points_per_proto))\n",
    "        else:\n",
    "            k = int(k_per_class)\n",
    "        k = max(1, min(k, len(X)))\n",
    "\n",
    "        centers, assign = _kmeans(X, k=k, seed=seed)\n",
    "        for j in range(len(centers)):\n",
    "            sj = (assign == j)\n",
    "            if not sj.any():\n",
    "                continue\n",
    "            mu = centers[j]\n",
    "            if normalize:\n",
    "                n = np.linalg.norm(mu)\n",
    "                if n > 0:\n",
    "                    mu = mu / (n + 1e-12)\n",
    "            weight = float(sj.mean())  # fraction of class points in this prototype\n",
    "            out.append({\"vector\": mu.astype(np.float32).tobytes(), \"label\": cls, \"weight\": weight})\n",
    "    return out\n",
    "\n",
    "def route_label(vec, labels, index, k=5):\n",
    "    means = {}\n",
    "    for lab in labels:\n",
    "        q = VectorQuery(\n",
    "            vector=list(map(float, vec)),\n",
    "            vector_field_name=\"vector\",\n",
    "            num_results=k,\n",
    "            return_fields=[\"label\", \"vector_distance\"],\n",
    "            filter_expression=f\"@label:{{{lab}}}\",\n",
    "        )\n",
    "        hits = index.query(q)\n",
    "        if hits:\n",
    "            dists = [float(h[\"vector_distance\"]) for h in hits]\n",
    "            means[lab] = sum(dists) / len(dists)\n",
    "    if not means:\n",
    "        return None, {}\n",
    "    best = min(means, key=means.get)\n",
    "    return best, means\n",
    "\n",
    "def route_batch(vectors, labels, index, k=5):\n",
    "    out = []\n",
    "    for v in tqdm(vectors):\n",
    "        best, _ = route_label(v, labels, index, k)\n",
    "        out.append(best)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcfcd7",
   "metadata": {},
   "source": [
    "### Pre-Generated Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b10c815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with timer.timeit(\"Load and process train data, create Redis Index\"):\n",
    "    r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=REDIS_DB)\n",
    "    try:\n",
    "        r.flushdb()\n",
    "        r.ft(redis_schema[\"index\"][\"name\"]).dropindex() \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    index = SearchIndex.from_dict(redis_schema, redis_url=REDIS_URL)\n",
    "    index.create(overwrite=True)\n",
    "    vectors,labels=load_embeddings_h5(train_filepath)\n",
    "    unique_labels=list(set(labels))\n",
    "    vectors = np.array(vectors)\n",
    "    data = build_multi_prototypes(vectors, labels, mask=None, k_per_class=5, max_points_per_proto=None, normalize=True, seed=0)\n",
    "\n",
    "    keys = index.load(data)\n",
    "index.info()['num_docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce3e5d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2039.42it/s]\n"
     ]
    }
   ],
   "source": [
    "with timer.timeit(\"Load and process test data\"):\n",
    "    test_vectors,test_labels=load_embeddings_h5(test_filepath, n=test_data.num_rows)\n",
    "    test_vectors = np.array(test_vectors)\n",
    "    test_vectors /= np.linalg.norm(test_vectors, axis=1, keepdims=True) + 1e-12\n",
    "with timer.timeit(\"Route test data\"):\n",
    "    preds=route_batch(test_vectors, unique_labels, index, k=5)\n",
    "\n",
    "eval_metrics = classification_metrics(\n",
    "    preds=preds,\n",
    "    labels=test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11190f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Experiment Summary: Semantic Routing Classification ===\n",
      "\n",
      "Timestamp         : 2025_10_15_164430\n",
      "\n",
      "DATA CONFIGURATION\n",
      "Router Name       : test\n",
      "Batch Size        : 1024\n",
      "Dataset Domain    : Sentiment\n",
      "Dataset Name      : MPQA\n",
      "Train Limit       : 8603\n",
      "Test Limit        : 2000\n",
      "Vector Dimensions : 128\n",
      "Embedding Model   : text-embedding-3-small\n",
      "\n",
      "REDIS SCHEMA\n",
      "Index Name        : MPQA\n",
      "Prefix            : test1\n",
      "Storage Type      : hash\n",
      "Fields:\n",
      "  - label (tag)\n",
      "  - vector (vector)  dims=128, metric=cosine, algo=hnsw\n",
      "\n",
      "REDIS INDEX INFO\n",
      "Documents         : 10\n",
      "Max Doc ID        : 10\n",
      "Num Terms         : 0\n",
      "Num Records       : 20\n",
      "Inverted Size (MB): 0.000164\n",
      "Vector Index (MB) : 0.724480\n",
      "\n",
      "EVALUATION METRICS\n",
      "Accuracy          : 0.8360\n",
      "Precision (macro) : 0.8361\n",
      "Recall (macro)    : 0.8360\n",
      "F1 (macro)        : 0.8360\n",
      "\n",
      "CONFUSION MATRIX [ [TP_0, FP_0], [FN_1, TP_1] ]\n",
      "  [827, 173]\n",
      "  [155, 845]\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "Class 0: Precision=0.842, Recall=0.827, F1=0.835, Support=1000\n",
      "Class 1: Precision=0.830, Recall=0.845, F1=0.837, Support=1000\n",
      "\n",
      "Macro Avg:\n",
      "  Precision=0.836, Recall=0.836, F1=0.836\n",
      "\n",
      "TIMINGS (seconds)\n",
      "load_dataset                                 : 2.126\n",
      "Embed and Save Train Data                    : 0.001\n",
      "Embed and Save Test Data                     : 0.000\n",
      "Load and process train data, create Redis Index: 0.334\n",
      "Load and process test data                   : 0.019\n",
      "Route test data                              : 0.982\n",
      "\n",
      "=============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'=== Experiment Summary: Semantic Routing Classification ===\\n\\nTimestamp         : 2025_10_15_164430\\n\\nDATA CONFIGURATION\\nRouter Name       : test\\nBatch Size        : 1024\\nDataset Domain    : Sentiment\\nDataset Name      : MPQA\\nTrain Limit       : 8603\\nTest Limit        : 2000\\nVector Dimensions : 128\\nEmbedding Model   : text-embedding-3-small\\n\\nREDIS SCHEMA\\nIndex Name        : MPQA\\nPrefix            : test1\\nStorage Type      : hash\\nFields:\\n  - label (tag)\\n  - vector (vector)  dims=128, metric=cosine, algo=hnsw\\n\\nREDIS INDEX INFO\\nDocuments         : 10\\nMax Doc ID        : 10\\nNum Terms         : 0\\nNum Records       : 20\\nInverted Size (MB): 0.000164\\nVector Index (MB) : 0.724480\\n\\nEVALUATION METRICS\\nAccuracy          : 0.8360\\nPrecision (macro) : 0.8361\\nRecall (macro)    : 0.8360\\nF1 (macro)        : 0.8360\\n\\nCONFUSION MATRIX [ [TP_0, FP_0], [FN_1, TP_1] ]\\n  [827, 173]\\n  [155, 845]\\n\\nCLASSIFICATION REPORT\\nClass 0: Precision=0.842, Recall=0.827, F1=0.835, Support=1000\\nClass 1: Precision=0.830, Recall=0.845, F1=0.837, Support=1000\\n\\nMacro Avg:\\n  Precision=0.836, Recall=0.836, F1=0.836\\n\\nTIMINGS (seconds)\\nload_dataset                                 : 2.126\\nEmbed and Save Train Data                    : 0.001\\nEmbed and Save Test Data                     : 0.000\\nLoad and process train data, create Redis Index: 0.334\\nLoad and process test data                   : 0.019\\nRoute test data                              : 0.982\\n\\n=============================================================\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_summary = print_experiment_summary(eval_metrics, redis_schema, router_config, timer.timings, index.info(), experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f860c1",
   "metadata": {},
   "source": [
    "# Option 2: OOTB Semantic Routing - The Offering from RedisVL, slight changes to handle more data bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b573c",
   "metadata": {},
   "source": [
    "### Custom Semantic Router - Allows messing with dimensions + batch sizes for bulky preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bfb00228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from tenacity.retry import retry_if_not_exception_type\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from redisvl.extensions.router import SemanticRouter\n",
    "from redisvl.extensions.router import Route\n",
    "from redisvl.utils.vectorize import OpenAITextVectorizer\n",
    "from redisvl.extensions.cache.embeddings.embeddings import EmbeddingsCache\n",
    "from datasets import load_dataset, Dataset\n",
    "from redisvl.extensions.router.schema import (\n",
    "    DistanceAggregationMethod,\n",
    "    Route,\n",
    "    RouteMatch\n",
    ")\n",
    "from redis.commands.search.aggregation import AggregateRequest, AggregateResult, Reducer\n",
    "from redisvl.redis.utils import hashify\n",
    "from redisvl.query import FilterQuery, VectorRangeQuery\n",
    "from redisvl.extensions.constants import ROUTE_VECTOR_FIELD_NAME\n",
    "from redis.exceptions import ResponseError\n",
    "from pydantic import PrivateAttr\n",
    "from collections import defaultdict\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import accumulate\n",
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class HighVisOpenAITextVectorizer(OpenAITextVectorizer):\n",
    "    _default_batch_size: int = PrivateAttr(1024)\n",
    "    _dimensions: int = PrivateAttr(1536)\n",
    "    def __init__(self, *args, default_batch_size: int = 1024, dimensions: int = 1536, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._default_batch_size = default_batch_size\n",
    "        self._dimensions = dimensions\n",
    "\n",
    "    @retry(\n",
    "    wait=wait_random_exponential(min=1, max=60),\n",
    "    stop=stop_after_attempt(6),\n",
    "    retry=retry_if_not_exception_type(TypeError),\n",
    "    )\n",
    "    def _embed_many(self, texts: List[str], batch_size: Optional[int] = None,\n",
    "                    dimensions: Optional[int] = None, **kwargs) -> List[List[float]]:\n",
    "        if not isinstance(texts, list) or (texts and not isinstance(texts[0], str)):\n",
    "            raise TypeError(\"Must pass in a list of str values to embed.\")\n",
    "        embeddings: List = []\n",
    "        pbar = tqdm(total=len(texts), unit=\"emb\", desc=\"Embedding\", disable=False)\n",
    "        for batch in tqdm(self.batchify(texts, self._default_batch_size)):\n",
    "            try:\n",
    "                resp = self._client.embeddings.create(input=batch, model=self.model, dimensions=self._dimensions, **kwargs)\n",
    "                embeddings += l2_normalize([r.embedding for r in resp.data])\n",
    "                pbar.update(len(batch))\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Embedding texts failed: {e}\")\n",
    "        pbar.close()\n",
    "        return embeddings\n",
    "\n",
    "class BigBatchSemanticRouter(SemanticRouter):\n",
    "\n",
    "    def _add_routes(self, routes: List[Route]):\n",
    "        \"\"\"Add routes to the router and index.\n",
    "\n",
    "        Args:\n",
    "            routes (List[Route]): List of routes to be added.\n",
    "        \"\"\"\n",
    "        route_references: List[Dict[str, Any]] = []\n",
    "        keys: List[str] = []\n",
    "\n",
    "        for route in routes:\n",
    "            # embed route references as a single batch\n",
    "            reference_vectors = self.vectorizer.embed_many(\n",
    "                [reference for reference in route.references], as_buffer=True\n",
    "            )\n",
    "            # set route references\n",
    "            for i, reference in enumerate(route.references):\n",
    "                reference_hash = hashify(reference)\n",
    "                route_references.append(\n",
    "                    {\n",
    "                        \"reference_id\": reference_hash,\n",
    "                        \"route_name\": route.name,\n",
    "                        \"reference\": reference,\n",
    "                        \"vector\": reference_vectors[i],\n",
    "                    }\n",
    "                )\n",
    "                keys.append(\n",
    "                    self._route_ref_key(self._index, route.name, reference_hash)\n",
    "                )\n",
    "            # set route if does not yet exist client side\n",
    "            if not self.get(route.name):\n",
    "                self.routes.append(route)\n",
    "        self._index.load(route_references, keys=keys)\n",
    "\n",
    "    def _get_route_matches(\n",
    "        self,\n",
    "        vector: List[float],\n",
    "        aggregation_method: DistanceAggregationMethod,\n",
    "        max_k: int = 1,\n",
    "    ) -> List[RouteMatch]:\n",
    "        \"\"\"Get route response from vector db\"\"\"\n",
    "\n",
    "        # what's interesting about this is that we only provide one distance_threshold for a range query not multiple\n",
    "        # therefore you might take the max_threshold and further refine from there.\n",
    "        distance_threshold = max(route.distance_threshold for route in self.routes)\n",
    "\n",
    "        vector_range_query = VectorRangeQuery(\n",
    "            vector=vector,\n",
    "            vector_field_name=ROUTE_VECTOR_FIELD_NAME,\n",
    "            distance_threshold=float(distance_threshold),\n",
    "            return_fields=[\"route_name\"],\n",
    "        )\n",
    "\n",
    "        aggregate_request = self._build_aggregate_request(\n",
    "            vector_range_query, aggregation_method, max_k=max_k\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            aggregation_result: AggregateResult = self._index.aggregate(\n",
    "                aggregate_request, vector_range_query.params\n",
    "            )\n",
    "        except ResponseError as e:\n",
    "            if \"VSS is not yet supported on FT.AGGREGATE\" in str(e):\n",
    "                raise RuntimeError(\n",
    "                    \"Semantic routing is only available on Redis version 7.x.x or greater\"\n",
    "                )\n",
    "            raise e\n",
    "\n",
    "        # process aggregation results into route matches\n",
    "        return [\n",
    "            self._process_route(route_match) for route_match in aggregation_result.rows\n",
    "        ]\n",
    "    \n",
    "    def _classify_multi_route(\n",
    "        self,\n",
    "        vector: List[float],\n",
    "        max_k: int,\n",
    "        aggregation_method: DistanceAggregationMethod,\n",
    "    ) -> List[RouteMatch]:\n",
    "        \"\"\"Classify to multiple routes, up to max_k (int), using a vector.\"\"\"\n",
    "\n",
    "        route_matches = self._get_route_matches(vector, aggregation_method, max_k=max_k)\n",
    "\n",
    "        # process route matches\n",
    "        top_route_matches: List[RouteMatch] = []\n",
    "        if route_matches:\n",
    "            for route_match in route_matches:\n",
    "                if route_match.name is not None:\n",
    "                    top_route_matches.append(route_match)\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        f\"{route_match.name} not a supported route for the {self.name} semantic router.\"\n",
    "                    )\n",
    "\n",
    "        return top_route_matches\n",
    "\n",
    "    def bulk_route(\n",
    "        self,\n",
    "        statements: Optional[List[str]] = None,\n",
    "        vectors: Optional[List[List[float]]] = None,\n",
    "        max_k: Optional[int] = None,\n",
    "        distance_threshold: Optional[float] = None,\n",
    "        aggregation_method: Optional[DistanceAggregationMethod] = None,\n",
    "    ) -> List[List[RouteMatch]]:\n",
    "        \"\"\"For mass routing.\n",
    "        \"\"\"\n",
    "        if not vectors:\n",
    "            if not statements:\n",
    "                raise ValueError(\"Must provide a list of vectors or statements to the router\")\n",
    "            vectors = self.vectorizer.embed_many(statements)  # type: ignore\n",
    "\n",
    "        max_k = max_k or self.routing_config.max_k\n",
    "        aggregation_method = (\n",
    "            aggregation_method or self.routing_config.aggregation_method\n",
    "        )\n",
    "\n",
    "        pbar = tqdm(total=len(vectors), unit=\"pred\", desc=\"Assessing\", disable=False)\n",
    "        results: List[List[RouteMatch]] = []\n",
    "        for v in vectors:\n",
    "            matches = self._classify_multi_route(v, max_k, aggregation_method)  # type: ignore\n",
    "            if distance_threshold is not None:\n",
    "                try:\n",
    "                    matches = [m for m in matches if m.distance <= distance_threshold]  # type: ignore\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "            results.append(matches)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "        return results\n",
    "\n",
    "\n",
    "    def bulk_democratic_route(\n",
    "        self,\n",
    "        statements: Optional[List[str]] = None,\n",
    "        vectors: Optional[List[List[float]]] = None,\n",
    "        max_k: Optional[int] = None,\n",
    "        distance_threshold: Optional[float] = None,\n",
    "        aggregation_method=None,\n",
    "    ) -> List[str]:\n",
    "        assert (statements or vectors) and not (statements and vectors)\n",
    "\n",
    "        max_k = 10\n",
    "        aggregation_method = aggregation_method or self.routing_config.aggregation_method\n",
    "\n",
    "        # 1) Build chunks and owners\n",
    "        if vectors is None:\n",
    "            all_chunks = []\n",
    "            owners = []\n",
    "            for i, s in enumerate(statements):\n",
    "                ch = chunk_texts([s])\n",
    "                all_chunks.extend(ch)\n",
    "                owners.extend([i] * len(ch))\n",
    "            # 2) Batch embed once\n",
    "            all_vecs = self.vectorizer.embed_many(all_chunks)\n",
    "        else:\n",
    "            # Caller pre-supplied vectors and owners must be 1:1 with statements\n",
    "            # Interpret each vector list item as a chunk of statement i\n",
    "            owners = []\n",
    "            all_vecs = []\n",
    "            for i, vecs_i in enumerate(vectors):\n",
    "                all_vecs.extend(vecs_i)\n",
    "                owners.extend([i] * len(vecs_i))\n",
    "\n",
    "        n_statements = (len(statements) if statements else (max(owners) + 1))\n",
    "        vote_counts = [defaultdict(float) for _ in range(n_statements)]\n",
    "\n",
    "        # 3) Classify chunks and accumulate votes by owner\n",
    "        pbar = tqdm(total=len(all_vecs), unit=\"chunk\", desc=\"Assessing\", disable=False)\n",
    "        for vec, owner in zip(all_vecs, owners):\n",
    "            matches = self._classify_multi_route(vec, max_k, aggregation_method)\n",
    "            for m in matches:\n",
    "                vote_counts[owner][m.name] += (m.distance ** 2)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "        # 4) Pick winners\n",
    "        preds = []\n",
    "        for vc in vote_counts:\n",
    "            if not vc:\n",
    "                preds.append(None)\n",
    "            else:\n",
    "                preds.append(min(vc, key=vc.get))\n",
    "        return preds\n",
    "\n",
    "\n",
    "def nuke_redis():\n",
    "    import redis\n",
    "    try:\n",
    "        r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=REDIS_DB)\n",
    "        r.flushdb()\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f61b81",
   "metadata": {},
   "source": [
    "### Custom Router Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59838920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Any, Callable, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "from ranx import Qrels, Run, evaluate\n",
    "from redisvl.extensions.router.semantic import SemanticRouter\n",
    "\n",
    "from redis_retrieval_optimizer.threshold_optimization.base import (\n",
    "    BaseThresholdOptimizer,\n",
    "    EvalMetric,\n",
    ")\n",
    "from redis_retrieval_optimizer.threshold_optimization.schema import LabeledData\n",
    "from redis_retrieval_optimizer.threshold_optimization.utils import (\n",
    "    NULL_RESPONSE_KEY,\n",
    "    _format_qrels,\n",
    ")\n",
    "\n",
    "\n",
    "def _generate_run_router(test_data: List[LabeledData], router: SemanticRouter) -> \"Run\":\n",
    "    \"\"\"Format router results into format for ranx Run\"\"\"\n",
    "    if Run is None:\n",
    "        raise ImportError(\"ranx is required for threshold optimization\")\n",
    "    if np is None:\n",
    "        raise ImportError(\"numpy is required for threshold optimization\")\n",
    "\n",
    "    run_dict: Dict[Any, Any] = {}\n",
    "\n",
    "    bulk_route = router.bulk_route(statements=[td.query for td in test_data], max_k=1)\n",
    "    print(len(bulk_route))\n",
    "    for td, match in zip(test_data, bulk_route):\n",
    "        run_dict[td.id] = {}\n",
    "        if match:\n",
    "            run_dict[td.id][match[0].name] = np.int64(1)\n",
    "        else:\n",
    "            run_dict[td.id][NULL_RESPONSE_KEY] = np.int64(1)\n",
    "\n",
    "    # for td in test_data:\n",
    "    #     run_dict[td.id] = {}\n",
    "    #     route_match = router(td.query)\n",
    "    #     if route_match and route_match.name == td.query_match:\n",
    "    #         run_dict[td.id][td.query_match] = np.int64(1)\n",
    "    #     else:\n",
    "    #         run_dict[td.id][NULL_RESPONSE_KEY] = np.int64(1)\n",
    "\n",
    "    return Run(run_dict)\n",
    "\n",
    "\n",
    "def _eval_router(\n",
    "    router: SemanticRouter,\n",
    "    test_data: List[LabeledData],\n",
    "    qrels: \"Qrels\",\n",
    "    eval_metric: str,\n",
    ") -> float:\n",
    "    \"\"\"Evaluate acceptable metric given run and qrels data\"\"\"\n",
    "    if evaluate is None:\n",
    "        raise ImportError(\"ranx is required for threshold optimization\")\n",
    "\n",
    "    run = _generate_run_router(test_data, router)\n",
    "    return evaluate(qrels, run, eval_metric, make_comparable=True)\n",
    "\n",
    "\n",
    "def _router_random_search(\n",
    "    route_names: List[str], route_thresholds: dict, search_step=0.10\n",
    "):\n",
    "    \"\"\"Performs random search for many thresholds to many routes\"\"\"\n",
    "    if np is None:\n",
    "        raise ImportError(\"numpy is required for threshold optimization\")\n",
    "\n",
    "    score_threshold_values = []\n",
    "    for route in route_names:\n",
    "        score_threshold_values.append(\n",
    "            np.linspace(\n",
    "                start=max(route_thresholds[route] - search_step, 0),\n",
    "                stop=route_thresholds[route] + search_step,\n",
    "                num=100,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        route: float(random.choice(score_threshold_values[i]))\n",
    "        for i, route in enumerate(route_names)\n",
    "    }\n",
    "\n",
    "\n",
    "def _random_search_opt_router(\n",
    "    router: SemanticRouter,\n",
    "    test_data: List[LabeledData],\n",
    "    qrels: \"Qrels\",\n",
    "    eval_metric: EvalMetric,\n",
    "    **kwargs: Any,\n",
    "):\n",
    "    \"\"\"Performs complete optimization for router cases provide acceptable metric\"\"\"\n",
    "    print(\"Starting Optimization\")\n",
    "\n",
    "    start_score = _eval_router(router, test_data, qrels, eval_metric.value)\n",
    "    best_score = start_score\n",
    "    best_thresholds = router.route_thresholds\n",
    "\n",
    "    max_iterations = kwargs.get(\"max_iterations\", 20)\n",
    "    search_step = kwargs.get(\"search_step\", 0.10)\n",
    "\n",
    "    pbar = tqdm(total=max_iterations, desc=\"Optimizing Routes\")\n",
    "    for _ in range(max_iterations):\n",
    "        route_names = router.route_names\n",
    "        route_thresholds = router.route_thresholds\n",
    "        thresholds = _router_random_search(\n",
    "            route_names=route_names,\n",
    "            route_thresholds=route_thresholds,\n",
    "            search_step=search_step,\n",
    "        )\n",
    "        router.update_route_thresholds(thresholds)\n",
    "        print(\"Eval starting\")\n",
    "        score = _eval_router(router, test_data, qrels, eval_metric.value)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thresholds = thresholds\n",
    "        pbar.update(1)\n",
    "\n",
    "    print(\n",
    "        f\"Eval metric {eval_metric.value.upper()}: start {round(start_score, 3)}, end {round(best_score, 3)} \\nEnding thresholds: {router.route_thresholds}\"\n",
    "    )\n",
    "    router.update_route_thresholds(best_thresholds)\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "class BulkRouterThresholdOptimizer(BaseThresholdOptimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        router: SemanticRouter,\n",
    "        test_dict: List[Dict[str, Any]],\n",
    "        opt_fn: Callable = _random_search_opt_router,\n",
    "        eval_metric: str = \"f1\",\n",
    "    ):\n",
    "        \"\"\"Initialize the router optimizer.\n",
    "\n",
    "        Args:\n",
    "            router (SemanticRouter): The RedisVL SemanticRouter instance to optimize.\n",
    "            test_dict (List[Dict[str, Any]]): List of test cases.\n",
    "            opt_fn (Callable): Function to perform optimization. Defaults to\n",
    "                grid search.\n",
    "            eval_metric (str): Evaluation metric for threshold optimization.\n",
    "                Defaults to \"f1\" score.\n",
    "        Raises:\n",
    "            ValueError: If the test_dict not in LabeledData format.\n",
    "        \"\"\"\n",
    "        super().__init__(router, test_dict, opt_fn, eval_metric)\n",
    "\n",
    "    def optimize(self, **kwargs: Any):\n",
    "        \"\"\"Optimize kicks off the optimization process for router\"\"\"\n",
    "        qrels = _format_qrels(self.test_data)\n",
    "        self.opt_fn(self.optimizable, self.test_data, qrels, self.eval_metric, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bdf937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92ea4cad",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4c33243",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuke_redis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e86d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, Column\n",
    "import re\n",
    "import string\n",
    "import tiktoken\n",
    "\n",
    "def standardize_strings(strings):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    cleaned = []\n",
    "    for s in strings:\n",
    "        s = s.lower()\n",
    "        s = s.translate(table)\n",
    "        s = re.sub(r'\\s+', ' ', s).strip()\n",
    "        cleaned.append(s)\n",
    "    return cleaned\n",
    "\n",
    "def l2_normalize(vectors):\n",
    "    vectors = np.asarray(vectors, dtype=np.float32)\n",
    "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "    normalized_vectors = vectors / norms\n",
    "    return normalized_vectors.tolist()\n",
    "\n",
    "def chunk_texts(texts, chunk_size=256, overlap=64, model=\"gpt-5\"):\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    chunks = []\n",
    "    for text in texts:\n",
    "        tokens = enc.encode(text)\n",
    "        for i in range(0, len(tokens), chunk_size):\n",
    "            chunk = enc.decode(tokens[i:i+chunk_size])\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def build_route(\n",
    "    references: list[str],\n",
    "    label: str,\n",
    "    priority: int = 1,\n",
    "    distance_threshold: float = 0.5\n",
    "    ) -> Route:\n",
    "  route = Route(\n",
    "      name=label,\n",
    "      references=references,\n",
    "      metadata={\"category\": label, \"priority\": priority},\n",
    "      distance_threshold=distance_threshold\n",
    "  )\n",
    "  return route\n",
    "\n",
    "def build_routes_from_hf_data(\n",
    "    dataset: Dataset,\n",
    "    text_col: str = \"text\",\n",
    "    label_col: str = \"label\",\n",
    "    distance_threshold: float = 0.5\n",
    "    ) -> list[Route]:\n",
    "    '''\n",
    "    Expects dataset to be of form:\n",
    "    Dataset({\n",
    "        features: ['text', 'label'],\n",
    "        num_rows: 343152\n",
    "    })\n",
    "    '''\n",
    "    df = dataset.to_pandas()[[text_col, label_col]]\n",
    "    texts_by_label = df.groupby(label_col)[text_col].apply(list).to_dict()\n",
    "    return [build_route(references=standardize_strings([str(i) if str(i).strip() != \"\" else \"0\" for i in refs]), label=str(lbl), distance_threshold=distance_threshold) for lbl, refs in texts_by_label.items()]\n",
    "\n",
    "\n",
    "eval_datasets={\n",
    "                \"Topic\": {\n",
    "                    \"DBLP\":{\n",
    "                        \"repo_id\": \"waashk/dblp\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "                      },\n",
    "                      \"20NG\":{\n",
    "                        \"repo_id\": \"waashk/20ng\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "                      },\n",
    "                      \"TREC\":{\n",
    "                        \"repo_id\": \"waashk/trec\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "                      },\n",
    "                      \"WOS-5736\":{\n",
    "                        \"repo_id\": \"waashk/wos5736\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "                      }\n",
    "                    },\n",
    "                \"Sentiment\": {\n",
    "                    \"SST-1\":{\n",
    "                        \"repo_id\": \"waashk/sst1\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "\n",
    "                    },\n",
    "                    \"SST-2\":{\n",
    "                        \"repo_id\": \"SetFit/sst2\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "\n",
    "                    },\n",
    "                    \"MPQA\":{\n",
    "                        \"repo_id\": \"jxm/mpqa\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"sentence\",\n",
    "                        \"label_col\": \"label\"\n",
    "                    }\n",
    "                },\n",
    "                \"Large\":{\n",
    "                    \"AGNews\":{\n",
    "                        \"repo_id\": \"SetFit/ag_news\",\n",
    "                        \"train_lbl\": \"train\",\n",
    "                        \"test_lbl\": \"test\",\n",
    "                        \"text_col\": \"text\",\n",
    "                        \"label_col\": \"label\"\n",
    "                    }\n",
    "                }\n",
    "              }\n",
    "\n",
    "router_config = {\n",
    "    \"name\": \"OOTB\",\n",
    "    \"batch_size\": 1024,\n",
    "    \"vectorizer_config\":{\n",
    "        \"dimensions\":1536,\n",
    "        \"OPENAI_API_KEY\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"OPENAI_MODEL\": \"text-embedding-3-small\"\n",
    "    },\n",
    "    \"dataset_domain\": \"Topic\",\n",
    "    \"dataset_name\": \"WOS-5736\",\n",
    "}\n",
    "\n",
    "experiment_notes = \"\"\n",
    "\n",
    "# dataset_repo_id = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"repo_id\"]\n",
    "# dataset = load_dataset(dataset_repo_id)\n",
    "# print(dataset)\n",
    "\n",
    "timer=Timer()\n",
    "\n",
    "with timer.timeit(\"load_dataset\"):\n",
    "    dataset_repo_id = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"repo_id\"]\n",
    "    dataset_train_lbl = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"train_lbl\"]\n",
    "    dataset_test_lbl = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"test_lbl\"]\n",
    "    dataset_text_col = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"text_col\"]\n",
    "    dataset_label_col = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"label_col\"]\n",
    "\n",
    "    # dataset = load_dataset(dataset_repo_id, data_files={\"train\":\"train_fold_0.parquet\", \"test\":\"test_fold_0.parquet\"})\n",
    "    dataset = load_dataset(dataset_repo_id)\n",
    "    # Merge dev with train\n",
    "    all_splits = list(dataset.keys())\n",
    "    extra_splits = [s for s in all_splits if s not in (dataset_train_lbl, dataset_test_lbl)]\n",
    "    if extra_splits:\n",
    "        train_data = concatenate_datasets([dataset[dataset_train_lbl]] + [dataset[s] for s in extra_splits])\n",
    "    else:\n",
    "        train_data = dataset[dataset_train_lbl]\n",
    "\n",
    "    if \"alternate_scoring_source\" in eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]]:\n",
    "        altdataset_repo_id = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"alternate_scoring_source\"][\"repo_id\"]\n",
    "        altdataset_test_lbl = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"alternate_scoring_source\"][\"test_lbl\"]\n",
    "        altdataset = load_dataset(altdataset_repo_id)\n",
    "        test_text_col = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"alternate_scoring_source\"][\"text_col\"]\n",
    "        test_label_col = eval_datasets[router_config[\"dataset_domain\"]][router_config[\"dataset_name\"]][\"alternate_scoring_source\"][\"label_col\"]\n",
    "        test_data = altdataset[altdataset_test_lbl]\n",
    "    else:\n",
    "        test_text_col = dataset_text_col\n",
    "        test_label_col = dataset_label_col\n",
    "        test_data = dataset[dataset_test_lbl]\n",
    "\n",
    "    router_config.update({\"dataset_repo_id\":dataset_repo_id})\n",
    "    router_config.update({\"train_limit\":dataset[dataset_train_lbl].num_rows})\n",
    "    router_config.update({\"test_limit\":dataset[dataset_test_lbl].num_rows})\n",
    "\n",
    "# Define Experiment Names\n",
    "safe_repo = dataset_repo_id.replace(\"/\", \"-\")\n",
    "experiment_name = f'{router_config[\"name\"]}_{safe_repo}_{router_config[\"vectorizer_config\"][\"OPENAI_MODEL\"]}_{router_config[\"vectorizer_config\"][\"dimensions\"]}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75e46dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 16954\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65dbe991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1892\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ef5bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuke_redis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a26b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 10669\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1186\n",
      "})\n",
      "Column([3, 1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(test_data)\n",
    "print(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c8dc25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:39:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:03,  3.72s/it]\n",
      "Embedding: 100%|██████████| 402/402 [00:03<00:00, 108.05emb/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:03,  3.45s/it]\n",
      "Embedding: 100%|██████████| 383/383 [00:03<00:00, 110.92emb/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:09 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:03,  3.27s/it]\n",
      "Embedding: 100%|██████████| 377/377 [00:03<00:00, 115.20emb/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:13 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:03,  3.01s/it]\n",
      "Embedding: 100%|██████████| 358/358 [00:03<00:00, 118.82emb/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:15 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:02,  2.65s/it]\n",
      "Embedding: 100%|██████████| 364/364 [00:02<00:00, 137.09emb/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:18 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:02,  2.78s/it]\n",
      "Embedding: 100%|██████████| 342/342 [00:02<00:00, 123.05emb/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:21 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assessing:   0%|          | 0/854 [13:39<?, ?chunk/s]\n",
      "Assessing:   0%|          | 0/854 [13:58<?, ?chunk/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:03,  3.70s/it]\n",
      "Embedding: 100%|██████████| 374/374 [00:03<00:00, 101.00emb/s]\n",
      "Embedding:   0%|          | 0/671 [00:00<?, ?emb/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:27 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.32s/it]████| 671/671 [00:04<00:00, 155.38emb/s]\n",
      "Embedding: 100%|██████████| 671/671 [00:04<00:00, 155.33emb/s]\n",
      "Embedding:   0%|          | 0/587 [00:00<?, ?emb/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:31 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.17s/it]████| 587/587 [00:04<00:00, 140.66emb/s]\n",
      "Embedding: 100%|██████████| 587/587 [00:04<00:00, 140.61emb/s]\n",
      "Embedding:   0%|          | 0/675 [00:00<?, ?emb/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:36 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.54s/it]████| 675/675 [00:05<00:00, 121.83emb/s]\n",
      "Embedding: 100%|██████████| 675/675 [00:05<00:00, 121.81emb/s]\n",
      "Embedding:   0%|          | 0/629 [00:00<?, ?emb/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40:41 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.60s/it]████| 629/629 [00:03<00:00, 174.90emb/s]\n",
      "Embedding: 100%|██████████| 629/629 [00:03<00:00, 174.84emb/s]\n"
     ]
    }
   ],
   "source": [
    "timer=Timer()\n",
    "\n",
    "with timer.timeit(\"Build Routes\"):\n",
    "    routes = build_routes_from_hf_data(dataset=train_data, text_col=dataset_text_col, label_col=dataset_label_col, distance_threshold=1)\n",
    "\n",
    "vectorizer=HighVisOpenAITextVectorizer(\n",
    "    model=router_config[\"vectorizer_config\"][\"OPENAI_MODEL\"],\n",
    "    api_config={\"api_key\": router_config[\"vectorizer_config\"][\"OPENAI_API_KEY\"]},\n",
    "    cache=EmbeddingsCache(redis_url=REDIS_URL),\n",
    "    default_batch_size=router_config[\"batch_size\"],\n",
    "    dimensions=router_config[\"vectorizer_config\"][\"dimensions\"]\n",
    ")\n",
    "\n",
    "with timer.timeit(\"Build Router\"):\n",
    "    router = BigBatchSemanticRouter(\n",
    "        name=router_config[\"name\"],\n",
    "        routes=routes,\n",
    "        vectorizer=vectorizer,\n",
    "        redis_url=REDIS_URL,\n",
    "        overwrite=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ecc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Optional for now\n",
    "'''\n",
    "\n",
    "# train_data_arr=[{\"query\": train_data[dataset_text_col][i], \"query_match\":str(train_data[dataset_label_col][i])} for i in range(len(train_data))]\n",
    "# optimizer = BulkRouterThresholdOptimizer(router, train_data_arr)\n",
    "# optimizer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f437f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:   0%|          | 0/574 [00:00<?, ?emb/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:41:24 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.38s/it]████| 574/574 [00:04<00:00, 131.01emb/s]\n",
      "Embedding: 100%|██████████| 574/574 [00:04<00:00, 130.97emb/s]\n",
      "Assessing: 100%|██████████| 574/574 [00:02<00:00, 267.92pred/s]\n"
     ]
    }
   ],
   "source": [
    "with timer.timeit(\"Predict using test data\"):\n",
    "    test_statements=standardize_strings([str(i) for i in test_data[test_text_col]])\n",
    "    # test_statements=[str(i) for i in test_data[test_text_col]]\n",
    "    preds = router.bulk_route(statements=test_statements, max_k=1)\n",
    "\n",
    "    \n",
    "    # preds = router.bulk_democratic_route(statements=test_statements, max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bda1700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Experiment Summary: Semantic Routing Classification ===\n",
      "\n",
      "Timestamp         : 2025_10_15_234131\n",
      "\n",
      "Experiment Notes  : NA\n",
      "\n",
      "DATA CONFIGURATION\n",
      "Router Name       : OOTB\n",
      "Batch Size        : 1024\n",
      "Dataset Repo ID    : waashk/wos5736\n",
      "Dataset Domain    : Topic\n",
      "Dataset Name      : WOS-5736\n",
      "Train Limit       : 5162\n",
      "Test Limit        : 574\n",
      "Vector Dimensions : 1536\n",
      "Embedding Model   : text-embedding-3-small\n",
      "\n",
      "\n",
      "No index info available\n",
      "EVALUATION METRICS\n",
      "Accuracy          : 0.6829\n",
      "Precision (macro) : 0.6447\n",
      "Recall (macro)    : 0.7030\n",
      "F1 (macro)        : 0.6560\n",
      "\n",
      "CONFUSION MATRIX [ [TP_0, FP_0], [FN_1, TP_1] ]\n",
      "  [40, 4, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "  [1, 36, 0, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "Class 0: Precision=0.769, Recall=0.889, F1=0.825, Support=45\n",
      "Class 1: Precision=0.706, Recall=0.837, F1=0.766, Support=43\n",
      "Class 10: Precision=0.546, Recall=0.929, F1=0.688, Support=70\n",
      "Class 2: Precision=0.796, Recall=0.929, F1=0.857, Support=42\n",
      "Class 3: Precision=0.685, Recall=0.949, F1=0.796, Support=39\n",
      "Class 4: Precision=0.841, Recall=0.925, F1=0.881, Support=40\n",
      "Class 5: Precision=0.743, Recall=0.684, F1=0.712, Support=38\n",
      "Class 6: Precision=0.000, Recall=0.000, F1=0.000, Support=42\n",
      "Class 7: Precision=0.704, Recall=0.253, F1=0.373, Support=75\n",
      "Class 8: Precision=0.686, Recall=0.738, F1=0.711, Support=65\n",
      "Class 9: Precision=0.616, Recall=0.600, F1=0.608, Support=75\n",
      "\n",
      "Macro Avg:\n",
      "  Precision=0.645, Recall=0.703, F1=0.656\n",
      "\n",
      "TIMINGS (seconds)\n",
      "Build Routes                                 : 0.137\n",
      "Build Router                                 : 44.195\n",
      "Predict using test data                      : 6.838\n",
      "Total: 51.170\n",
      "\n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_preds = [i[0].name if len(i)>0 else \"0\" for i in preds]\n",
    "# extracted_preds = preds\n",
    "labels = [str(i) for i in test_data[test_label_col]]\n",
    "\n",
    "eval_metrics = classification_metrics(\n",
    "    preds=extracted_preds,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "exp_summary = print_experiment_summary(eval_metrics, router_config, timer.timings, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9daaab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
